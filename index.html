<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Fei Shang </title> <meta name="author" content="Fei Shang"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%98%BA&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zaoanhh.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Fei</span> Shang </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 135.0px, (min-width: 576px) 15vw, 95vw"> <img src="/assets/img/prof_pic.jpg?3be0145774bd78047051490ab3f6d3e3" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>ÂêõÂ≠êÈ£üÊó†Ê±ÇÈ•±ÔºåÂ±ÖÊó†Ê±ÇÂÆâÔºåÊïè‰∫é‰∫ãËÄå‰∏çËÆ∑‰∫éË®ÄÔºåÂ∞±ÊúâÈÅìËÄåÊ≠£ÁÑâ</p> </div> </div> <div class="clearfix"> <p>I am fortunate to be advised by Prof. <a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;user=sst3cxoAAAAJ" rel="external nofollow noopener" target="_blank">Panlong Yang</a> and Prof. <a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;user=JURtNb0AAAAJ" rel="external nofollow noopener" target="_blank">Xiang-Yang Li</a> at University of Science and Technology of China (USTC). My research interest is wireless sensing.</p> <h3 id="awards">Awards</h3> <ul> <li>Young Elite Scientists Sponsorship Program by CAST - Doctoral Student Special Plan (First session), 2024</li> <li>National Scholarship, 2022, 2024</li> <li>Intel Scholarship, 2023</li> <li>Outstanding Graduate Student of Anhui Province, 2025</li> </ul> <h3 id="service">Service</h3> <ul> <li>Reviewer of IEEE IoTJ, IEEE TMC, IMWUT/Ubicomp, ACM TIoT</li> <li>The host at the BIGCOM Rising Star Forum, 2024</li> </ul> <h3 id="news">News</h3> <ul> <li>[2025.04] üéâüéâüéâ Our paper ‚ÄúThe field-based model: a new perspective on RF-based material sensing‚Äù has been accepted by <code class="language-plaintext highlighter-rouge">SCIS</code>.</li> <li>[2025.04] üéâüéâüéâ Our paper ‚ÄúMeasuring Discrete Sensing Capability for ISAC via Task Mutual Information‚Äù has been accepted by <code class="language-plaintext highlighter-rouge">SCIS</code>.</li> <li>[2025.02] üéâüéâüéâ Our paper ‚ÄúPushing the Limits of WiFi-based Gait Recognition Towards Non-gait Human Behaviors‚Äù has been accepted by <code class="language-plaintext highlighter-rouge">IEEE TMC</code>.</li> </ul> </div> <h2> <a href="/publications/" style="color: inherit">Selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> SCIS </abbr> </div> <div id="shang2024fieldbasedmodelnewperspective" class="col-sm-8"> <div class="title">The Field-based Model: A New Perspective on RF-based Material Sensing</div> <div class="author"> <em>Fei Shang</em>,¬†Haocheng Jiang,¬†Panlong Yang, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Dawei Yan, Haohua Du, Xiang-Yang Li' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> Apr 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2412.05640" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">shang2024fieldbasedmodelnewperspective</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Field-based Model: A New Perspective on RF-based Material Sensing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shang, Fei and Jiang, Haocheng and Yang, Panlong and Yan, Dawei and Du, Haohua and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2412.05640}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{eess.SP}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2412.05640}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> SCIS </abbr> </div> <div id="shang2025measuringdiscretesensingcapability" class="col-sm-8"> <div class="title">Measuring discrete sensing capability for ISAC via task mutual information</div> <div class="author"> <em>Fei Shang</em>,¬†Haohua Du,¬†Panlong Yang, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Xin He, Jingjing Wang, Xiang-Yang Li' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>SCIENCE CHINA Information Sciences</em>, Apr 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/https://doi.org/10.1007/s11432-024-4374-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/DTMI-all.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">shang2025measuringdiscretesensingcapability</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Measuring discrete sensing capability for ISAC via task mutual information}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shang, Fei and Du, Haohua and Yang, Panlong and He, Xin and Wang, Jingjing and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{SCIENCE CHINA Information Sciences}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Science and Business Media LLC}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1869-1919}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{68}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{150308-}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.sciengine.com/publisher/Science China Press/journal/SCIENCE CHINA Information Sciences/68/5/10.1007/s11432-024-4374-y}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s11432-024-4374-y}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> IEEE TMC </abbr> </div> <div id="yan2025anteumbler" class="col-sm-8"> <div class="title">Non-Intrusive and Efficient Estimation of Antenna 3-D Orientation for WiFi APs</div> <div class="author"> Dawei Yan,¬†Panlong Yang,¬†<em>Fei Shang</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Nikolaos M. Freris, Yubo Yan' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing</em>, Mar 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TMC.2024.3485228" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Anteumbler_TMC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The effectiveness of WiFi-based localization systems heavily relies on the spatial accuracy of WiFi AP. In real-world scenarios, factors such as AP rotation and irregular antenna tilt contribute significantly to inaccuracies, surpassing the impact of imprecise AP location and antenna separation. In this paper, we propose Anteumbler, a non-invasive, accurate, and efficient system for measuring the orientation of each antenna in physical space. By leveraging the fact that maximum received power occurs when a Tx-Rx antenna pair is perfectly aligned, we build a spatial angle model capable of determining antennas‚Äô orientations without prior knowledge. However, achieving comprehensive coverage across the spatial angle necessitates extensive sampling points. To enhance efficiency, we exploit the orthogonality of antenna directivity and polarization, and adopt an iterative algorithm, thereby reducing the number of sampling points by several orders of magnitude. Additionally, to attain the required antenna orientation accuracy, we mitigate the influence of propagation distance using a dual plane intersection model while filtering out ambient noise. Our real-world experiments, covering six antenna types, two antenna layouts, two antenna separations (Œª/2Œª/2 and \lambdaŒª ), and three AP heights, demonstrate that Anteumbler achieves median errors below \text6^\circ6‚àò for both elevation and azimuth angles, and exhibits robustness in NLoS and dynamic environments. Moreover, when integrated into the reverse localization system, Anteumbler deployed over LocAP reduces antenna separation error by 10 \,\mathrmmm10 mm , while for user localization system, its integration over SpotFi reduces user localization error by more than 1 \,\mathrmm1m.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yan2025anteumbler</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yan, Dawei and Yang, Panlong and Shang, Fei and Freris, Nikolaos M. and Yan, Yubo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Mobile Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Non-Intrusive and Efficient Estimation of Antenna 3-D Orientation for WiFi APs}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1453-1468}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Antenna measurements;Antennas;Location awareness;Wireless fidelity;Receiving antennas;Accuracy;Antenna arrays;Sensors;Manuals;Dipole antennas;Antenna orientation;polarization matching;WiFi localization}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2024.3485228}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-0660}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> IEEE TMC </abbr> </div> <div id="freegait-tmc" class="col-sm-8"> <div class="title"> Pushing the Limits of WiFi-Based Gait Recognition Towards Non-Gait Human Behaviors </div> <div class="author"> Dawei Yan,¬†Panlong Yang,¬†<em>Fei Shang</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Feiyu Han, Yubo Yan, Xiang-Yang Li' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em> IEEE Transactions on Mobile Computing </em>, Feb 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TMC.2025.3540863" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/freegaitTMC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p> WiFi-based gait recognition technologies have seen significant advancements in recent years. However, most existing approaches rely on a critical assumption: users must walk continuously and maintain a consistent body posture. This poses a substantial challenge when users engage in non-periodic or discontinuous behaviors (e.g., stopping, starting, or turning mid-walk), which can disrupt the extraction of gait-related features and degrade recognition performance. To address this issue, we propose freeGait, a novel approach designed to mitigate the impact of non-gait behaviors in WiFi-based gait recognition systems. Our solution models this problem as domain adaptation, where we learn domain-independent representations to isolate gait features from behavior-dependent noise. We treat human behaviors with labeled user data as source domains and behaviors without user labels as target domains. However, applying domain adaptation directly is challenging due to the ambiguous classification boundaries in the target domains for WiFi signals. To overcome this, we align the posterior distributions between the source and target domains and constrain the conditional distribution within the target domains to enhance gait classification accuracy. Additionally, we implement a data augmentation module to generate data resembling the labeled data, while supervised learning ensures distinctiveness between users. Our experiments, conducted with 20 participants across 3 different scenarios, demonstrate that freeGait can accurately predict data across 15 domains by labeling only a small subset from 6 source domains, achieving up to a 45% improvement in user classification accuracy compared to existing methods. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">freegait-tmc</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yan, Dawei and Yang, Panlong and Shang, Fei and Han, Feiyu and Yan, Yubo and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ IEEE Transactions on Mobile Computing }</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{ Pushing the Limits of WiFi-Based Gait Recognition Towards Non-Gait Human Behaviors }}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{01}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-0660}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-17}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Behavioral sciences;Legged locomotion;Gait recognition;Wireless fidelity;Feature extraction;Transceivers;Accuracy;Noise;Working environment noise;Sensors}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2025.3540863}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.ieeecomputersociety.org/10.1109/TMC.2025.3540863}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE Computer Society}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Los Alamitos, CA, USA}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">JCRD</abbr> </div> <div id="iotsurvey" class="col-sm-8"> <div class="title">Survey on Low Power Sensing of AIoT</div> <div class="author"> Xiangyang Li,¬†<em>Fei Shang</em>,¬†Yubo Yan, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Shanyue Wang, Feiyu Han, Guoxuan Chi, Zheng Yang, Xiaojiang Chen' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Jisuanji Yanjiu yu Fazhan/Computer Research and Development</em>, Nov 2024 </div> <div class="periodical"> Artificial intelligence of thing;Digital analog drive;Internet of thing;Large-scales;Low-power consumption;Low-power sensing;Lower-power consumption;Mobile-computing;Sensing;Sensing modalities; </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.7544/issn1000-1239.202440396" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/IotSurvey.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>With the deepening integration of human-machine-object fusion, an increasing number of lightweight and large-scale sensing demands are emerging. To meet the deployment needs of multiple scenarios and large scales, low-cost and low-power sensing solutions are becoming increasingly favored. However, there are still some common and specific challenges in the field of low-power sensing that hinder their further development and practical application. Although many excellent reviews have been conducted on a specific sensing modality or application, there is still a lack of work that sorts out the entire field of low-power sensing. In this paper, we summarize recent low-power sensing, introduce three types of sensing modalities including inertial measurement unit (IMU), microphone, and radio frequency signals, summarize their related challenges, and introduce relevant solutions from hardware and software levels. Finally, we introduce the applications of sensing schemes in different scenarios from four aspects: surface sensing, property sensing, physiological sensing, and anti-sensing, along the direction from surface to inside, from object to human body, and from sensing to safety, and summarize several prospects for exploration.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">iotsurvey</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{Chinese}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{Compendex}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Survey on Low Power Sensing of AIoT}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Jisuanji Yanjiu yu Fazhan/Computer Research and Development}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xiangyang and Shang, Fei and Yan, Yubo and Wang, Shanyue and Han, Feiyu and Chi, Guoxuan and Yang, Zheng and Chen, Xiaojiang}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{61}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2754 - 2775}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{10001239}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Artificial intelligence of thing;Digital analog drive;Internet of thing;Large-scales;Low-power consumption;Low-power sensing;Lower-power consumption;Mobile-computing;Sensing;Sensing modalities;}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dx.doi.org/10.7544/issn1000-1239.202440396}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.7544/issn1000-1239.202440396}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b509ac;color:var(--global-card-bg-color) !important;"> SenSys </abbr> </div> <div id="Forum" class="col-sm-8"> <div class="title">Ph.D. Forum: Field Sensing Model, A New Foundation for RF Sensing</div> <div class="author"> <em>Fei Shang</em> </div> <div class="periodical"> <em>In Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems</em>, Hangzhou, China, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3666025.3699668" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Sensys_Phd.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In recent years, radio frequency (RF) signal-based sensing has garnered significant attention due to its ubiquity, with numerous applications emerging in areas such as target localization, material recognition, and health monitoring. However, current sensing models are often based on ray tracing, which, although computationally convenient, can become severely distorted when the target size is not much larger than the wavelength. Additionally, using signals with smaller wavelengths to mitigate this issue is not always feasible. Noting that RF signals are a form of electromagnetic waves, we have explored the development of field sensing models directly based on Maxwell‚Äôs equations. These models can finely characterize phenomena such as diffraction and multiple scattering, thereby enhancing the upper limits of sensing system capabilities. Based on this approach, we have achieved integrated material recognition and imaging of centimeter-scale targets using WiFi signals. This work has been accepted for presentation at Ubicomp 2024.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Forum</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shang, Fei}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Ph.D. Forum: Field Sensing Model, A New Foundation for RF Sensing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400706974}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3666025.3699668}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3666025.3699668}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{920‚Äì922}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{wireless sensing, radio frequency, field model}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Hangzhou, China}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{SenSys '24}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> Ubicomp </abbr> </div> <div id="EarSpeech" class="col-sm-8"> <div class="title">EarSpeech: Exploring In-Ear Occlusion Effect on Earphones for Data-efficient Airborne Speech Enhancement</div> <div class="author"> Feiyu Han,¬†Panlong Yang,¬†You Zuo, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Fei Shang, Fenglei Xu, Xiang-Yang Li' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</em>, Sep 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3678594" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/EarSpeech.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Earphones have become a popular voice input and interaction device. However, airborne speech is susceptible to ambient noise, making it necessary to improve the quality and intelligibility of speech on earphones in noisy conditions. As the dual-microphone structure (i.e., outer and in-ear microphones) has been widely adopted in earphones (especially ANC earphones), we design EarSpeech which exploits in-ear acoustic sensory as the complementary modality to enable airborne speech enhancement. The key idea of EarSpeech is that in-ear speech is less sensitive to ambient noise and exhibits a correlation with airborne speech. However, due to the occlusion effect, in-ear speech has limited bandwidth, making it challenging to directly correlate with full-band airborne speech. Therefore, we exploit the occlusion effect to carry out theoretical modeling and quantitative analysis of this cross-channel correlation and study how to leverage such cross-channel correlation for speech enhancement. Specifically, we design a series of methodologies including data augmentation, deep learning-based fusion, and noise mixture scheme, to improve the generalization, effectiveness, and robustness of EarSpeech, respectively. Lastly, we conduct real-world experiments to evaluate the performance of our system. Specifically, EarSpeech achieves an average improvement ratio of 27.23% and 13.92% in terms of PESQ and STOI, respectively, and significantly improves SI-SDR by 8.91 dB. Benefiting from data augmentation, EarSpeech can achieve comparable performance with a small-scale dataset that is 40 times less than the original dataset. In addition, we validate the generalization of different users, speech content, and language types, respectively, as well as robustness in the real world via comprehensive experiments. The audio demo of EarSpeech is available on https://github.com/EarSpeech/earspeech.github.io/.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">EarSpeech</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Han, Feiyu and Yang, Panlong and Zuo, You and Shang, Fei and Xu, Fenglei and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{EarSpeech: Exploring In-Ear Occlusion Effect on Earphones for Data-efficient Airborne Speech Enhancement}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{September 2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3678594}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3678594}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{104}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Earphone-based Sensing and Computing, In-ear Acoustic Sensing, Occlusion Effect, Speech Enhancement}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b509ac;color:var(--global-card-bg-color) !important;"> MobiHoc </abbr> </div> <div id="freeGait" class="col-sm-8"> <div class="title">freeGait: Liberalizing Wireless-based Gait Recognition to Mitigate Non-gait Human Behaviors</div> <div class="author"> Dawei Yan,¬†Panlong Yang,¬†<em>Fei Shang</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Feiyu Han, Yubo Yan, Xiang-Yang Li' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Twenty-Fifth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing</em>, Athens, Greece, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3641512.3686362" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/freegait.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Recently, WiFi-based gait recognition technologies have been widely studied. However, most of them work on a strong assumption that users need to walk continuously and periodically under a constant body posture. Thus, a significant challenge arises when users engage in non-periodic or discontinuous behaviors (e.g., stopping and going, turning around during walking). This is because variations of non-gait behaviors interfere with the extraction of gait-related features, resulting in recognition performance degradation. To solve this problem, we propose freeGait, which aims to mitigate the user‚Äôs non-gait behaviors of WiFi-based gait recognition system. Specifically, we model this problem as domain adaptation, by learning domain-independent representations to extract behavior-independent gait features. We consider human behaviors with labels of users as source domains, and human behaviors without labels of users as target domains. However, directly applying domain adaptation to our specific problem is challenging, because the classification boundaries of the unknown target domains are unclear for WiFi signals. We align the posterior distributions of the source and target domains, and constrain the conditional distribution of the target domains to optimize the gait classification accuracy. To obtain enough source domains data, we build a data augmentation module to generate data similar to the labeled data, and use supervised learning to make the data different between users. We conduct experiments with 20 people and 3 different scenarios, and the results show that accurate predictions of a total of 15 domains data can be achieved by only collecting and labeling a small amount of data from 6 source domains, and user classification accuracy can be improved by up to 45% compared to other existing techniques.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">freeGait</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yan, Dawei and Yang, Panlong and Shang, Fei and Han, Feiyu and Yan, Yubo and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{freeGait: Liberalizing Wireless-based Gait Recognition to Mitigate Non-gait Human Behaviors}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400705212}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3641512.3686362}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3641512.3686362}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Twenty-Fifth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{241‚Äì250}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{wifi-based sensing, gait recognition, domain adaptation, data augmentation}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Athens, Greece}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{MobiHoc '24}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> IEEE TMC </abbr> </div> <div id="LiqRay-TMC" class="col-sm-8"> <div class="title">Contactless and Fine-Grained Liquid Identification Utilizing Sub-6 GHz Signals</div> <div class="author"> <em>Fei Shang</em>,¬†Panlong Yang,¬†Yubo Yan, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Xiang-Yang Li' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>IEEE Transactions on Mobile Computing</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TMC.2023.3300356" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Contactless.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The existing RF-based liquid identification systems usually rely on prior knowledge, such as pre-build database or the material and width information of the vessel. Furthermore, existing methods may not work in scenarios where the height of liquid is smaller than that of antenna. In this paper, we proposes LiqRay^++, a contactless system which can identify liquids in a fine-grained level without prior knowledge. To remove the effect of vessel, we build a dual-antenna model and craft a relative frequency response factor, exploring diversity of the permittivity in frequency domain. To eliminate the effect of different height, we devise the electric field distribution model at the receiving antenna, solving the unknown heights via spatio-differential model. Among eight different solvents, LiqRay^++ can identify alcohol solutions with a concentration difference of 1% with 92.9% accuracy. Even if the liquid height is about 4 cm, which is fairly lower than that of most antennas‚Äô heights, the accuracy is more than 85%.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">LiqRay-TMC</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shang, Fei and Yang, Panlong and Yan, Yubo and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Mobile Computing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Contactless and Fine-Grained Liquid Identification Utilizing Sub-6 GHz Signals}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{23}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4992-5008}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Liquids;Transmitting antennas;Attenuation;Antennas;Receiving antennas;Electric fields;Electromagnetic scattering;Contactless;fine-grained;liquid identification;wireless sensing}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMC.2023.3300356}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-0660}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> Ubicomp </abbr> </div> <div id="LiquImager" class="col-sm-8"> <div class="title">LiquImager: Fine-grained Liquid Identification and Container Imaging System with COTS WiFi Devices</div> <div class="author"> <em>Fei Shang</em>,¬†Panlong Yang,¬†Dawei Yan, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Sijia Zhang, Xiang-Yang Li' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3643509" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/LiquImager.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/LiquImager_slide.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>WiFi has gradually developed into one of the main candidate technologies for ubiquitous sensing. Based on commercial off-the-shelf (COTS) WiFi devices, this paper proposes LiquImager, which can simultaneously identify liquid and image container regardless of container shape and position. Since the container size is close to the wavelength, diffraction makes the effect of the liquid on the signal difficult to approximate with a simple geometric model (such as ray tracking). Based on Maxwell‚Äôs equations, we construct an electric field scattering sensing model. Using few measurements provided by COTS WiFi devices, we solve the scattering model to obtain the medium distribution of the sensing domain, which is used for identifing and imaging liquids. To suppress the signal noise, we propose LiqU-Net for image enhancement. For the centimeter-scale container that is randomly placed in an area of 25 cm \texttimes 25 cm, LiquImager can identify the liquid more than 90% accuracy. In terms of container imaging, LiquImager can accurately find the edge of the container for 4 types of containers with a volume less than 500 ml.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">LiquImager</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shang, Fei and Yang, Panlong and Yan, Dawei and Zhang, Sijia and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LiquImager: Fine-grained Liquid Identification and Container Imaging System with COTS WiFi Devices}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{March 2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3643509}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3643509}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Complex permittivity, Electromagnetic waves, Liquid identification, Wireless sensing}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> Ubicomp </abbr> </div> <div id="Wi-Painter" class="col-sm-8"> <div class="title">Wi-Painter: Fine-grained Material Identification and Image Delineation Using COTS WiFi Devices</div> <div class="author"> Dawei Yan,¬†Panlong Yang,¬†<em>Fei Shang</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Weiwei Jiang, Xiang-Yang Li' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3633809" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Wi-Painter.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/Wi-Painter_slide.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>WiFi has gradually developed into one of the main candidate technologies for indoor environment sensing. In this paper, we are interested in using COTS WiFi devices to identify material details, including location, material type, and shape, of stationary objects in the surrounding environment, which may open up new opportunities for many applications. Specifically, we present Wi-Painter, a model-driven system that can accurately detects smooth-surfaced material types and their edges using COTS WiFi devices without modification. Different from previous arts for material identification, Wi-Painter subdivides the target into individual 2D pixels, and simultaneously forms a 2D image based on identifying the material type of each pixel. The key idea of Wi-Painter is to exploit the complex permittivity of the object surface which can be estimated by the different reflectivity of signals with different polarization directions. In particular, we construct the multi-incident angle model to characterize the material, using only the power ratios of the vertically and horizontally polarized signals measured at several different incident angles, which avoids the use of inaccurate WiFi signal phases. We implement and evaluate Wi-Painter in the real world, showing an average classification accuracy of 93.4% for different material types including metal, wood, rubber and plastic of different sizes and thicknesses, and across different environments. In addition, Wi-Painter can accurately detect the material type and edge of the word "LOVE" spliced with different materials, with an average size of 60cm \texttimes 80cm, and material edges with different orientations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Wi-Painter</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yan, Dawei and Yang, Panlong and Shang, Fei and Jiang, Weiwei and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wi-Painter: Fine-grained Material Identification and Image Delineation Using COTS WiFi Devices}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{December 2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3633809}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3633809}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{203}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Complex permittivity, Material identification, Object imaging, Wireless sensing}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b509ac;color:var(--global-card-bg-color) !important;"> ACM TOSN </abbr> </div> <div id="Tamera" class="col-sm-8"> <div class="title">Tamera: Contactless Commodity Tracking, Material and Shopping Behavior Recognition Using COTS RFIDs</div> <div class="author"> <em>Fei Shang</em>,¬†Panlong Yang,¬†Jie Xiong, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yuanhao Feng, Xiangyang Li' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>ACM Trans. Sen. Netw.</em>, Feb 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3563777" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Tamera.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>RFID technology has recently been exploited for not only identification but also fine-grained trajectory tracking and gesture recognition. While contact-based¬†(a tag is attached to the target of interest) sensing has achieved promising results, contactless sensing still faces severe challenges such as low accuracy and inability to sense multiple targets simultaneously in proximity, restricting its applicability in real-world deployment. In this work, we present Tamera, a contactless RFID-based sensing system, which significantly improves the tracking accuracy, enables multi-commodity tracking, and even material and shopping behavior recognition. We successfully address multiple technical challenges, and design and implement our prototype on commodity RFID devices. We test the positioning accuracy of Tamera in a 5 m \texttimes 6 m laboratory. Tamera achieves a median error of 1.3 cm and 2.7 cm for contactless single- and multi-commodity tracking, respectively. In our laboratory, two shelves commonly found in the supermarket are arranged and the goods are placed on them. Tamera successfully localizes and identifies the material type (metal, plastic, paper, and glass) of the commodities on the shelf with an accuracy higher than 95%. Tamera successfully recognizes four shopping behaviors (taking commodity, replacing commodity, buying commodity, and invoking commodity) with an accuracy higher than 93%.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Tamera</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shang, Fei and Yang, Panlong and Xiong, Jie and Feng, Yuanhao and Li, Xiangyang}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tamera: Contactless Commodity Tracking, Material and Shopping Behavior Recognition Using COTS RFIDs}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{May 2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1550-4859}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3563777}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3563777}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Trans. Sen. Netw.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{43}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{shopping behavior, material, sensing, tracking, contactless, RFID}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> Ubicomp </abbr> </div> <div id="PackquID" class="col-sm-8"> <div class="title">PackquID: In-packet Liquid Identification Using RF Signals</div> <div class="author"> <em>Fei Shang</em>,¬†Panlong Yang,¬†Yubo Yan, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Xiang-Yang Li' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</em>, Jan 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3569469" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Packquid.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>There are many scenarios where the liquid is occluded by other items (e.g. books in a packet), in which existing RF-based liquid identification methods are generally not suitable. Moreover, status methods are not applicable when the height of the liquid to be tested changes. This paper proposes PackquID, an RF-based in-packet liquid identification system, which can identify liquid without prior knowledge. In dealing with the obstruction of other items and the unknown container, we utilize a dual-antenna model and craft a relative frequency response factor, exploring the diversity of the permittivity in the frequency domain. In tackling the variable liquid height, we extend our model to 3D scope by analyzing the electric field distribution and solving the height effect via spatial-differential model. With 500 pages of printer paper obscured, PackquID can identify 9 common liquids, including Coca-Cola and Pepsi, with an accuracy of over 86% for 4 different packets (canvas bag, paper bag, backpack, and box) and 4 different containers. Nevertheless, PackquID can still identify liquids with an accuracy rate of over 87%, even when the liquid height changes from 4 cm to 12 cm.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PackquID</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shang, Fei and Yang, Panlong and Yan, Yubo and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PackquID: In-packet Liquid Identification Using RF Signals}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{December 2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3569469}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3569469}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{181}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{27}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Complex permittivity, Electromagnetic waves, Liquid identification, Wireless sensing}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff3636;color:var(--global-card-bg-color) !important;"> MobiCom </abbr> </div> <div id="liqray" class="col-sm-8"> <div class="title">LiqRay: non-invasive and fine-grained liquid recognition system</div> <div class="author"> <em>Fei Shang</em>,¬†Panlong Yang,¬†Yubo Yan, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Xiang-Yang Li' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 28th Annual International Conference on Mobile Computing And Networking</em>, Sydney, NSW, Australia, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3495243.3560540" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/LiqRay.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/LiqRay_slide.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>The existing RF-based liquid identification methods commonly require a training network of liquid or the container information, such as material and width. Moreover, status quo methods are inapplicable when the solution height is lower than that of the antenna, which is generally unknown either. This paper proposes LiqRay, an RF-based solution, retaining non-invasive and fine-grained liquid recognition abilities, thus can recognize unknown solutions without prior knowledge. In dealing with the unknown container material and width, we utilize a dual-antenna model and craft a relative frequency response factor, exploring diversity of the permittivity in frequency domain. In tackling the unknown heights of solution and antenna, we devise the electric field distribution model at the receiving antenna, solving the unknown heights via spatio-differential model. Among eight different solvents, LiqRay can identify alcohol solutions with a concentration difference of 1% with 94.92% accuracy. Nevertheless, LiqRay can obtain the relative frequency response factor with a relative error of 6.7% without being affected by the height of the solution. Even if it is merely 4 cm, this is fairly lower than that of most antennas‚Äô heights, since the operating frequency is around 2 GHz.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liqray</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shang, Fei and Yang, Panlong and Yan, Yubo and Li, Xiang-Yang}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LiqRay: non-invasive and fine-grained liquid recognition system}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450391818}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3495243.3560540}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3495243.3560540}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 28th Annual International Conference on Mobile Computing And Networking}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{296‚Äì309}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{wireless sensing, material identification, liquid identification, contactless sensing, complex permittivity}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Sydney, NSW, Australia}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{MobiCom '22}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%73%68%66_%31%39%39%38@%6F%75%74%6C%6F%6F%6B.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/zaoanhh" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://orcid.org/0000-0002-5495-8869" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=bj1rUJYAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Fei Shang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>